<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title> • foehnix</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<script src="../extra.js"></script><meta property="og:title" content="">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">foehnix</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/foehnix.html">Getting started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/foehnix.html">Foehnix Demo</a>
    </li>
    <li>
      <a href="../articles/plotting.html">Plotting Functions</a>
    </li>
    <li>
      <a href="../articles/tsplot.html">[Plot] Time Series</a>
    </li>
    <li>
      <a href="../articles/image.html">[Plot] Hovmöller Diagram</a>
    </li>
    <li>
      <a href="../articles/simulation.html">Simulation Examples</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/mixedmodel.html">Statistical Model</a>
    </li>
    <li>
      <a href="../articles/logisticregression.html">Logistic Regression (IWLS)</a>
    </li>
    <li>
      <a href="../articles/inference.html">Inference</a>
    </li>
    <li>
      <a href="../articles/advanced_simulation.html">Censoring and Truncation</a>
    </li>
    <li>
      <a href="../articles/families.html">foehnix Families</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/retostauffer/Rfoehnix">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1></h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/retostauffer/Rfoehnix/blob/master/../vignettes/logisticregression.Rmd"><code>../vignettes/logisticregression.Rmd</code></a></small>
      <div class="hidden name"><code>logisticregression.Rmd</code></div>

    </div>

    
    
<div id="logistic-regression-with-iterative-re-weighted-least-squares" class="section level2">
<h2 class="hasAnchor">
<a href="#logistic-regression-with-iterative-re-weighted-least-squares" class="anchor"></a>Logistic Regression with Iterative (re-)Weighted Least Squares</h2>
<p>Logistic regression (LR) models are generalized linear models and often used for binary response models where an observation <span class="math inline">\(\mathit{y}\)</span> is binary zero or one. The logit-link is used as cannonical link to ensure that the modelled probabilities <span class="math inline">\(\mathit{\pi}\)</span> lie within <span class="math inline">\(]0, 1[\)</span>. <span class="math inline">\(\pi_i\)</span> for a specific observation <span class="math inline">\(i \in \{1, \dots, N\}\)</span> is the probability that we will observe <span class="math inline">\(y_i = 1\)</span>. The model can be written as follows:</p>
<ul>
<li>
<span class="math inline">\(\log\big(\frac{\mathit{\pi}}{1 - \mathit{\pi}}\big) = \mathbf{x}^\top \mathit{\alpha}~~\)</span> or <span class="math inline">\(~~\pi = \frac{\exp(\mathbf{x}^\top \mathit{\alpha})}{1 + \exp(\mathbf{x}^\top \mathit{\alpha})}\)</span>.</li>
</ul>
<p><span class="math inline">\(\mathit{\alpha}\)</span> is a vector of length <span class="math inline">\(P\)</span> of regression coefficients, <span class="math inline">\(\mathbf{x}\)</span> a matrix of dimension <span class="math inline">\(N \times P\)</span> containing the covariates. Given as set of observations <span class="math inline">\(\mathit{y} \in \{0, 1\}\)</span> and the corresponding covariates <span class="math inline">\(\mathbf{x}\)</span> the regression coefficients <span class="math inline">\(\mathit{\alpha}\)</span> can be estimated using e.g., maximum likelihood. The log-likelihood sum of the LR model can be written as follows:</p>
<ul>
<li>
<span class="math inline">\(\ell(\mathit{\alpha}~|~\mathit{y}, \mathbf{x}) = \sum_{i=1}^N \big( \mathit{y} \mathbf{x}^\top \mathit{\alpha} -  \log(1 + \exp(\mathbf{x}^\top \mathit{\alpha})) \big)\)</span>.</li>
</ul>
</div>
<div id="fitting-logistic-regression-models" class="section level2">
<h2 class="hasAnchor">
<a href="#fitting-logistic-regression-models" class="anchor"></a>Fitting Logistic Regression Models</h2>
<p>The parameters of binary LR models can be estimated using an interative (re-)Weighted least squares (IWLS) solver. The regression coefficients <span class="math inline">\(\mathit{\alpha}\)</span> are iteratively updated using a Newton-Raphson update procedure. A single Newton update (one single iteration) is:</p>
<ul>
<li><span class="math inline">\(\mathit{\alpha}^{(j+1)} = \mathit{\alpha}^{(j)} - \Big(\frac{\partial^2\ell(\mathit{\alpha})}{\partial\mathit{\alpha}\partial\mathit{\alpha}^\top}\Big)^{-1} \frac{\partial\ell(\mathit{\alpha})}{\partial\mathit{\alpha}}\)</span></li>
</ul>
<p>Where the derivates are evaluated at <span class="math inline">\(\mathit{\alpha}^{(j)}\)</span> from the previouse iteration. The first order and second order derivatives of the log-likelihood are:</p>
<ul>
<li><span class="math inline">\(\frac{\partial\ell(\mathit{\alpha})}{\partial\mathit{\alpha}} = \sum_{i=1}^N x_i \big(y_i - \frac{\exp(\mathit{x}_i^\top \mathit{\alpha})}{1 + \exp(\mathit{x}_i^\top \mathit{\alpha})}\big) = \sum_{i=1}^N x_i (y_i - \pi_i)\)</span></li>
<li><span class="math inline">\(\frac{\partial^2\ell(\mathit{\alpha})}{\partial\mathit{\alpha}\partial\mathit{\alpha}^\top} = \sum_{i=1}^N x_i^2 \big(\frac{\exp(\mathit{x}_i^\top \mathit{\alpha})^2}{(1 + \exp(\mathit{x}_i^\top \mathit{\alpha}))^2} - \frac{\exp(\mathit{x}_i^\top \mathit{\alpha})}{1 + \exp(\mathit{x}_i^\top \mathit{\alpha})}\big) = - \sum_{i=1}^N x_i^2 \pi_i (1 - \pi_i)\)</span></li>
</ul>
<p>The same can be written in matrix notation:</p>
<ul>
<li>
<span class="math inline">\(\frac{\partial^2\ell(\mathit{\alpha})}{\partial\mathit{\alpha}\partial\mathit{\alpha}^\top} = - \mathbf{x}^\top \mathbf{w} \mathbf{x}\)</span>, <span class="math inline">\(~~~\frac{\partial\ell(\mathit{\alpha})}{\partial\mathit{\alpha}} = \mathbf{x}^\top (\mathit{y} - \mathit{\pi})\)</span>
</li>
</ul>
<p>… where <span class="math inline">\(\mathbf{w}\)</span> is an <span class="math inline">\(N \times N\)</span> diagonal matrix of weights with the diagonal elements <span class="math inline">\(\mathit{\pi} (1 - \mathit{\pi})\)</span> evaluated at <span class="math inline">\(\mathit{\alpha}^{(j)}\)</span>. Thus, the Newton step in matrix notation is given as:</p>
<ul>
<li><span class="math inline">\(\mathit{\alpha}^{(j+1)} = \mathit{\alpha}^{(j)} + (\mathbf{x}^\top \mathbf{w} \mathbf{x})^{-1} \mathbf{x}^\top (\mathit{y} - \mathit{\pi}) = (\mathbf{x}^\top \mathbf{w} \mathbf{x})^{-1} \mathbf{x}^\top \mathbf{w} (\mathbf{x}\mathit{\alpha}^{(j)} + \mathbf{w}^{-1} (\mathit{y} - \mathit{\pi}))\)</span></li>
</ul>
<p>With <span class="math inline">\(\tilde{\mathbf{w}} = \mathbf{w}^\frac{1}{2}\)</span> (<span class="math inline">\(\mathbf{w} = \tilde{\mathbf{w}}^2\)</span>) we can write the Newton step as:</p>
<ul>
<li>
<span class="math inline">\(\mathit{\alpha}^{(j+1)} = (\mathbf{x}^\top \tilde{\mathbf{w}} \tilde{\mathbf{w}} \mathbf{x})^{-1} \mathbf{x}^\top \tilde{\mathbf{w}} (\underbrace{\mathbf{x} \tilde{\mathbf{w}} \mathit{\alpha}^{(j)} + \tilde{\mathbf{w}}^{-1} (\mathit{y} - \mathit{\pi})}_{\text{weighted adjusted response}})\)</span>.</li>
</ul>
<p>With <span class="math inline">\(\mathbf{x^*} = \mathbf{x} \tilde{\mathbf{w}}\)</span> and <span class="math inline">\(z = \mathbf{x} \tilde{\mathbf{w}} \mathit{\alpha}^{(j)} + \tilde{\mathbf{w}}^{-1} (\mathit{y} - \mathit{\pi})\)</span> the equation can be rewritten as:</p>
<ul>
<li><span class="math inline">\(\mathit{\alpha}^{(j+1)} = (\mathbf{x}^{*\top} \mathbf{x}^*)^{-1} \mathbf{x}^{*\top} \mathit{z}\)</span></li>
</ul>
<p>… similar to ordinary least squares.</p>
</div>
<div id="iwls-algorithm" class="section level2">
<h2 class="hasAnchor">
<a href="#iwls-algorithm" class="anchor"></a>IWLS Algorithm</h2>
<p>Given the equations above the iterative algorithm can be written as follows:</p>
<p>Initialization</p>
<ol style="list-style-type: decimal">
<li>Initialize <span class="math inline">\(\mathit{\alpha}^{(0)} = 0\)</span> (set all coefficients to zero)</li>
<li>Initialize <span class="math inline">\(\mathit{\pi}^{(0)} = 0.5\)</span> (<span class="math inline">\(\mathit{\pi}^{(0)} = \frac{\exp(\mathbf{x}^\top \mathit{\alpha}^{(0)})}{1 + \exp(\mathbf{x}^\top \mathit{\alpha}^{(0)})}\)</span>)</li>
</ol>
<p>Update step for iteration <span class="math inline">\(j = 1, \dots, \text{maxit}\)</span>:</p>
<ol start="3" style="list-style-type: decimal">
<li>Update weights: <span class="math inline">\(\tilde{\mathbf{w}}^{(j)} = \big(\mathit{\pi}^{(j-1)} (1 - \mathit{\pi}^{(j-1)})\big)^\frac{1}{2}\)</span>
</li>
<li>Update weighted adjusted response: <span class="math inline">\(\mathit{z}^{(j)} = \mathbf{x} \tilde{\mathbf{w}}^{(j)} \mathit{\alpha}^{(j-1)} + (\tilde{\mathbf{w}}^{(j)})^{-1} (\mathit{y} - \mathit{\pi}^{(j-1)})\)</span>
</li>
<li>Update coefficients: <span class="math inline">\(\mathit{\alpha}^{(j)} = (\mathbf{x}^\top \tilde{\mathbf{w}}^{(j)} \tilde{\mathbf{w}}^{(j)} \mathbf{x})^{-1} \mathbf{x}^\top \tilde{\mathbf{w}}^{(j)} \mathit{z}^{(j)}\)</span>
</li>
<li>Calculate likelihood: <span class="math inline">\(\ell^{(j)}\)</span>. If <span class="math inline">\(j = 1\)</span> proceed with <strong>step 3</strong>.</li>
<li>For <span class="math inline">\(j &gt; 1\)</span>: if <span class="math inline">\((\ell^{(j)} - \ell^{(j-1)}) &lt; \text{tol}\)</span> the likelihood could not have been improved in this iteration (converged or stuck): stop IWLS algorithm and return <span class="math inline">\(\mathit{\alpha}^{(j-1)}\)</span>. If <span class="math inline">\(j = \text{maxit}\)</span>: maximum number of iterations reached, stop algorith and return <span class="math inline">\(\mathit{\alpha}^{(j)}\)</span>. Else proceed with <strong>step 3</strong> until one of the stopping criteria is reached.</li>
</ol>
<p>The <a href="../reference/iwls_logit.html">manual page of the iwls_logit function</a> contains a practical example. More details about the IWLS procedure can be found in <a href="../index.html#hastie2009">Hastie, Tibshirani, and Friedman (2009, Chap. 4.4.1)</a>, <a href="../index.html#mccullagh1999">McCullagh and Nelder (1999, Chap. 4.4)</a>, and many other statistical text books (see <a href="../index.html#references">References</a> for details).</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#logistic-regression-with-iterative-re-weighted-least-squares">Logistic Regression with Iterative (re-)Weighted Least Squares</a></li>
      <li><a href="#fitting-logistic-regression-models">Fitting Logistic Regression Models</a></li>
      <li><a href="#iwls-algorithm">IWLS Algorithm</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Reto Stauffer.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
